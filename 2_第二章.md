# 2.1
解：$C_{500}^{350}*C_{500}^{350}$
# 2.2
解：使用十折交叉验证，将样本集划分为十个子集，从每个子集的正负样本的数学期望数都是5，那么用九个子集去估计剩余的一个子集，九个子集的正负样本数相等，则估计的话即是随机猜测。因此用10折交叉验证法的错误率的数学期望为0.5。  
使用留一法，去掉一个正样本，则留下的样本中负样本多，去掉一个负样本，留下的正样本多。因此预测总会出错。故错误率为1.0。
# 2.4
|  | 预测正例 | 预测反例 |
| ------ | ------ | ------ |
| 实际正例 | TP(True Positive) | FN(False Negative) |
| 实际反例 | FP | TN |  
则查准率为$P=TP/(TP+FP)$，查全率为$R=TP/(TP+FN)$，真正例率为$TPR=TP/(TP+FN)$，假正例率为$FPR=FP/(TN+FP)$。    
从实际意义来看，查准率为预测正例中真正正例的占比，即以正例为标准的准确率，查全率则是真正正例中预测正例的占比，即以正例为标准的全面性。我们希望二者都尽量高，然而二者却一般是矛盾的。为了提高查准率，我们可以提高预测阈值，这样可以确保预测准确，但一些真正正例可能会被抛弃，造成查全率减少。反正我们降低阈值，肯定会提高查准率，但查全率又可能减少。  
真正例率，顾名思义，预测正例中正确的（是真正正例）的样本，占所有正例的比率。假正例率，预测正例中错误的（是反例）的样本，占所有反例的比率。我们希望前者尽可能大，而后者尽可能小。然而，二者一定程度上是正比关系。要提高真正例率，往往要降低预测阈值，这便会可能将一些真正反例预测为正例，使假正例率降低。  
用上面的四个参数，可以十分有效地衡量一个二分类模型的预测能力。具体是，画出P-R曲线和TPR-FPR曲线，画这两个的曲线的方式为：  
先按是正例的可能性对样本进行排序（升序降序都可以），然后将预测为正值的阈值从零开始逐渐提高（对应离散样本中，从为正例的可能性最高的开始，逐一预测为正样本的过程）。每发生一次变动，便计算相应的值，最后在图中表示出来。  
P-R曲线经过(1,1)点和TPR-FPR曲线经过(0,1)点都是代表，按照概率排序后，实际正样本为正的概率比实际负样本为正的概率要大，即模型可以完全地分辨出正负样本。而P-R曲线的$y=-x+1$和ROC曲线的$y=x$都是表示一个随机猜测的模型（至少其正确率和随机猜测相同）。  
一般地，若一个模型的P-R曲线或ROC曲线（TPR-FPR曲线）完全包含另一个模型的对应曲线，则可以说该模型较优。如果有交叉的情况，可考虑ROC曲线下面积，即AUC(Area Under ROC Curve)，AUC考虑的是样本预测的排序质量，AUC越大，排序质量越高，模型越好。特别地，若面积为1，即模型为一个过(0,1)点的矩形，说明模型可以精准预测。
# 2.8
Min-max规范化：  
优点：1.压缩到的目标区间可以灵活选择。2.每当有新的元素进来，只有该元素大于最大值或者小于最小值时才要重新计算全部元素。  
缺点：1.由于区间的选择是任意的，因此数据之间潜在的大小关系可能会被破坏。2.若最大值过大或最小值过小，则规范化后数据分布仍会很畸形。  
z-score规范化：  
优点：1.不改变原始数据的分布。  
缺点：1.每当有新数据进来时，需要重新计算均值和方差。  
